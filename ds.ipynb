{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T08:19:11.191855Z",
     "start_time": "2024-04-19T08:19:10.546543Z"
    }
   },
   "source": [
    "from data_utils import CQADatasetLoader, SVAMPDatasetLoader, ESNLIDatasetLoader, ANLI1DatasetLoader, ASDivDatasetLoader\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T08:19:11.194458Z",
     "start_time": "2024-04-19T08:19:11.192736Z"
    }
   },
   "source": [
    "dataset_loader = ESNLIDatasetLoader()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T08:19:14.497991Z",
     "start_time": "2024-04-19T08:19:11.195062Z"
    }
   },
   "source": [
    "dataset = dataset_loader.load_from_json()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "train_llm_rationales, train_llm_labels = dataset_loader.load_llm_preds(split='train')\n",
    "test_llm_rationales, test_llm_labels = dataset_loader.load_llm_preds(split='test')\n",
    "valid_llm_rationales, valid_llm_labels = dataset_loader.load_llm_preds(split='valid')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:19:15.041900Z",
     "start_time": "2024-04-19T08:19:14.498914Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "dataset['train'] = dataset['train'].add_column('llm_label', train_llm_labels)\n",
    "dataset['test'] = dataset['test'].add_column('llm_label', test_llm_labels)\n",
    "dataset['train'] = dataset['train'].add_column('llm_rationale', train_llm_rationales)\n",
    "dataset['test'] = dataset['test'].add_column('llm_rationale', test_llm_rationales)\n",
    "dataset['valid'] = dataset['valid'].add_column('llm_label', valid_llm_labels)\n",
    "dataset['valid'] = dataset['valid'].add_column('llm_rationale', valid_llm_rationales)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:19:15.897310Z",
     "start_time": "2024-04-19T08:19:15.043544Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "id2label = {0: \"contradiction\", 1: \"entailment\", 2: \"neutral\"}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:19:15.899613Z",
     "start_time": "2024-04-19T08:19:15.897881Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "from t5_enc.t5 import T5ForConditionalGenerationAndSequenceClassification\n",
    "\n",
    "model = T5ForConditionalGenerationAndSequenceClassification.from_pretrained(\"google/flan-t5-small\", num_labels=3,\n",
    "                                                                            id2label=id2label, label2id=label2id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:27:07.864462Z",
     "start_time": "2024-04-19T08:27:06.093634Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'id2label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mt5_enc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mt5\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m T5ForConditionalGenerationAndSequenceClassification\n\u001B[1;32m      3\u001B[0m model \u001B[38;5;241m=\u001B[39m T5ForConditionalGenerationAndSequenceClassification\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgoogle/flan-t5-small\u001B[39m\u001B[38;5;124m\"\u001B[39m, num_labels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,\n\u001B[0;32m----> 4\u001B[0m                                                                             id2label\u001B[38;5;241m=\u001B[39m\u001B[43mid2label\u001B[49m, label2id\u001B[38;5;241m=\u001B[39mlabel2id)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'id2label' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:19:19.006459Z",
     "start_time": "2024-04-19T08:19:18.581873Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset.map(\n",
    "    lambda example: {'input': tokenizer.eos_token.join([example['premise'], example['hypothesis']])},\n",
    "    remove_columns=['premise', 'hypothesis'],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:19:29.766240Z",
     "start_time": "2024-04-19T08:19:19.007115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/549367 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e269cc8af7b84ccea95653181be787ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:19:29.768765Z",
     "start_time": "2024-04-19T08:19:29.766854Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'llm_label', 'llm_rationale', 'input'],\n",
       "        num_rows: 549367\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'llm_label', 'llm_rationale', 'input'],\n",
       "        num_rows: 9824\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['label', 'llm_label', 'llm_rationale', 'input'],\n",
       "        num_rows: 9842\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "def tokenize_function(examples):\n",
    "    model_inputs = tokenizer(examples['input'], max_length=512, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        rationale_output_encodings = tokenizer(examples['llm_rationale'], max_length=256, truncation=True)\n",
    "\n",
    "    model_inputs['labels'] = rationale_output_encodings['input_ids']\n",
    "    model_inputs['label'] = [label2id[e] for e in examples['label']]\n",
    "\n",
    "    return model_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:19:29.770832Z",
     "start_time": "2024-04-19T08:19:29.769240Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_function,\n",
    "    remove_columns=['input', 'llm_label', 'llm_rationale', 'label'],\n",
    "    batched=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:20:08.688867Z",
     "start_time": "2024-04-19T08:19:29.771362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/549367 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be14274599cf4ad5b2f58c138b7af09b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/artembatalov/miniconda3/envs/thesis/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3935: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_datasets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:20:08.691390Z",
     "start_time": "2024-04-19T08:20:08.689448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 549367\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9824\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9842\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T08:20:08.718060Z",
     "start_time": "2024-04-19T08:20:08.693957Z"
    }
   },
   "source": [
    "from transformers import Seq2SeqTrainingArguments, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    remove_unused_columns = False,\n",
    "    evaluation_strategy = 'steps',\n",
    "    eval_steps=15,\n",
    "    save_steps=15,\n",
    "    save_total_limit=3,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=15,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=5e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    # metric_for_best_model=\"test_accuracy\",\n",
    "    gradient_accumulation_steps=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    seed=0,\n",
    "    prediction_loss_only=False,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:20:08.720232Z",
     "start_time": "2024-04-19T08:20:08.718641Z"
    }
   },
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "p = None\n",
    "def compute_metrics(eval_pred):\n",
    "    global p\n",
    "    predictions, labels = eval_pred\n",
    "    print(predictions)\n",
    "    p = predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:20:08.722356Z",
     "start_time": "2024-04-19T08:20:08.720788Z"
    }
   },
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "trainer_kwargs = {\n",
    "    'alpha': 0.5,\n",
    "    'model': model,\n",
    "    'args': training_args,\n",
    "    'train_dataset': tokenized_datasets[\"train\"],\n",
    "    'eval_dataset': {'test': tokenized_datasets[\"test\"],},\n",
    "    'data_collator': data_collator,\n",
    "    'tokenizer': tokenizer,\n",
    "    'compute_metrics': compute_metrics,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:20:08.724463Z",
     "start_time": "2024-04-19T08:20:08.722836Z"
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "from t5_enc.t5 import MyTrainer\n",
    "\n",
    "trainer = MyTrainer(**trainer_kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T08:23:10.832539Z",
     "start_time": "2024-04-19T08:23:10.618022Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/artembatalov/miniconda3/envs/thesis/lib/python3.11/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T08:25:25.146704Z",
     "start_time": "2024-04-19T08:25:05.161490Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='103008' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [     3/103008 00:06 < 179:24:36, 0.16 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/transformers/trainer.py:1780\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1778\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[1;32m   1779\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1780\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1781\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1782\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1783\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1784\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1785\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/transformers/trainer.py:2118\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2115\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_begin(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[1;32m   2117\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39maccumulate(model):\n\u001B[0;32m-> 2118\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   2121\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[1;32m   2122\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[1;32m   2123\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[1;32m   2124\u001B[0m ):\n\u001B[1;32m   2125\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[1;32m   2126\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/transformers/trainer.py:3036\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[0;34m(self, model, inputs)\u001B[0m\n\u001B[1;32m   3033\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss_mb\u001B[38;5;241m.\u001B[39mreduce_mean()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m   3035\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss_context_manager():\n\u001B[0;32m-> 3036\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3038\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mn_gpu \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3039\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mmean()  \u001B[38;5;66;03m# mean() to average on multi-gpu parallel training\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/thesis/t5_enc/t5.py:393\u001B[0m, in \u001B[0;36mMyTrainer.compute_loss\u001B[0;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[1;32m    392\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_loss\u001B[39m(\u001B[38;5;28mself\u001B[39m, model, inputs, return_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 393\u001B[0m     outputs: Seq2SeqLMAndSequenceClassificationOutput \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    394\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malpha \u001B[38;5;241m*\u001B[39m outputs\u001B[38;5;241m.\u001B[39mclf_loss \u001B[38;5;241m+\u001B[39m (\u001B[38;5;241m1.\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malpha) \u001B[38;5;241m*\u001B[39m outputs\u001B[38;5;241m.\u001B[39mloss\n\u001B[1;32m    395\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (loss, outputs) \u001B[38;5;28;01mif\u001B[39;00m return_outputs \u001B[38;5;28;01melse\u001B[39;00m loss\n",
      "File \u001B[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/thesis/t5_enc/t5.py:288\u001B[0m, in \u001B[0;36mT5ForConditionalGenerationAndSequenceClassification.forward\u001B[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, label, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    283\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mtie_word_embeddings:\n\u001B[1;32m    284\u001B[0m     \u001B[38;5;66;03m# Rescale output before projecting on vocab\u001B[39;00m\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/transformer.py#L586\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     sequence_output \u001B[38;5;241m=\u001B[39m sequence_output \u001B[38;5;241m*\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_dim \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m0.5\u001B[39m)\n\u001B[0;32m--> 288\u001B[0m lm_logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlm_head\u001B[49m\u001B[43m(\u001B[49m\u001B[43msequence_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    290\u001B[0m lm_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    291\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 116\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(nan, dtype=float32), array([[[-43.344982  ,  -3.823163  ,  -9.568947  , ..., -43.30296   ,\n",
      "         -43.30662   , -43.20291   ],\n",
      "        [-36.69597   ,  -3.203759  ,  -6.599506  , ..., -36.667812  ,\n",
      "         -36.73565   , -36.495316  ],\n",
      "        [-41.270657  ,  -3.4887917 ,  -7.1263914 , ..., -41.15655   ,\n",
      "         -41.26951   , -41.065056  ],\n",
      "        ...,\n",
      "        [-35.18772   ,  -2.294404  ,  -5.536607  , ..., -35.1947    ,\n",
      "         -35.2855    , -35.026443  ],\n",
      "        [-50.82319   ,  -2.5226564 ,  -9.210549  , ..., -50.89539   ,\n",
      "         -50.91757   , -50.807384  ],\n",
      "        [-56.56958   ,   1.0558381 , -10.8807125 , ..., -56.66071   ,\n",
      "         -56.6109    , -56.714474  ]],\n",
      "\n",
      "       [[-44.159786  ,  -3.5050118 ,  -8.90931   , ..., -44.143486  ,\n",
      "         -44.124977  , -44.057106  ],\n",
      "        [-37.438126  ,  -3.5394063 ,  -7.564574  , ..., -37.42482   ,\n",
      "         -37.477608  , -37.265823  ],\n",
      "        [-41.715214  ,  -3.9664586 ,  -7.501052  , ..., -41.614082  ,\n",
      "         -41.708603  , -41.544415  ],\n",
      "        ...,\n",
      "        [-49.483173  ,  -0.08584404,  -9.619297  , ..., -49.53051   ,\n",
      "         -49.58071   , -49.362324  ],\n",
      "        [-49.611706  ,  -0.22114934,  -9.768104  , ..., -49.66238   ,\n",
      "         -49.705566  , -49.498276  ],\n",
      "        [-49.71227   ,  -0.38281536,  -9.91269   , ..., -49.76366   ,\n",
      "         -49.801773  , -49.605003  ]],\n",
      "\n",
      "       [[-44.413044  ,  -4.194376  ,  -9.094317  , ..., -44.349403  ,\n",
      "         -44.35561   , -44.264828  ],\n",
      "        [-38.035503  ,  -3.4364905 ,  -6.8287106 , ..., -37.993847  ,\n",
      "         -38.067543  , -37.82274   ],\n",
      "        [-43.587406  ,  -4.357458  ,  -8.256995  , ..., -43.439903  ,\n",
      "         -43.568058  , -43.365593  ],\n",
      "        ...,\n",
      "        [-46.66123   ,  -2.807324  , -12.853701  , ..., -46.643764  ,\n",
      "         -46.7065    , -46.663006  ],\n",
      "        [-46.514633  ,  -2.8402553 , -12.788838  , ..., -46.49331   ,\n",
      "         -46.552284  , -46.51066   ],\n",
      "        [-46.595707  ,  -2.9722874 , -12.69135   , ..., -46.569733  ,\n",
      "         -46.62605   , -46.58436   ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-48.48785   ,  -4.5261    ,  -9.44652   , ..., -48.387894  ,\n",
      "         -48.424328  , -48.28462   ],\n",
      "        [-43.252678  ,  -5.3167243 ,  -7.1441035 , ..., -43.13225   ,\n",
      "         -43.1866    , -42.94702   ],\n",
      "        [-44.20127   ,  -4.2225485 ,  -6.741743  , ..., -44.02388   ,\n",
      "         -44.129776  , -43.918983  ],\n",
      "        ...,\n",
      "        [-59.890915  ,   1.0212985 , -11.13602   , ..., -59.95037   ,\n",
      "         -59.909706  , -59.985645  ],\n",
      "        [-57.594162  ,  -3.0305932 ,  -7.627721  , ..., -57.69395   ,\n",
      "         -57.6425    , -57.440407  ],\n",
      "        [-58.61064   ,  -4.5362973 , -13.107576  , ..., -58.573803  ,\n",
      "         -58.641235  , -58.50544   ]],\n",
      "\n",
      "       [[-47.876877  ,  -4.4770284 ,  -9.064692  , ..., -47.772545  ,\n",
      "         -47.8163    , -47.673332  ],\n",
      "        [-44.018406  ,  -5.2445393 ,  -7.6284547 , ..., -43.888885  ,\n",
      "         -43.97114   , -43.737816  ],\n",
      "        [-48.06356   ,  -5.825006  ,  -7.401404  , ..., -47.889496  ,\n",
      "         -48.040607  , -47.825283  ],\n",
      "        ...,\n",
      "        [-50.91712   ,   1.294766  , -11.200172  , ..., -50.82089   ,\n",
      "         -50.89657   , -50.664677  ],\n",
      "        [-50.834553  ,   1.113169  , -11.134001  , ..., -50.734325  ,\n",
      "         -50.80951   , -50.584175  ],\n",
      "        [-50.811775  ,   0.98736763, -11.063872  , ..., -50.709923  ,\n",
      "         -50.78464   , -50.563374  ]],\n",
      "\n",
      "       [[-44.09912   ,  -4.996298  , -10.116752  , ..., -44.052334  ,\n",
      "         -44.010067  , -44.035706  ],\n",
      "        [-38.625786  ,  -4.819197  ,  -5.813288  , ..., -38.56778   ,\n",
      "         -38.569798  , -38.405903  ],\n",
      "        [-39.722183  ,  -4.0468597 ,  -5.5148625 , ..., -39.654366  ,\n",
      "         -39.724613  , -39.570354  ],\n",
      "        ...,\n",
      "        [-57.493324  ,  -3.4794927 , -12.998023  , ..., -57.534267  ,\n",
      "         -57.52979   , -57.468163  ],\n",
      "        [-56.360928  ,  -3.527153  , -12.729198  , ..., -56.38862   ,\n",
      "         -56.38277   , -56.308506  ],\n",
      "        [-55.601814  ,  -3.5789032 , -12.496808  , ..., -55.618744  ,\n",
      "         -55.612255  , -55.529087  ]]], dtype=float32), array([[0.0335678 , 0.01864622,        nan],\n",
      "       [0.0328612 , 0.0174779 ,        nan],\n",
      "       [0.03275478, 0.0177695 ,        nan],\n",
      "       [0.03334741, 0.01615101,        nan],\n",
      "       [0.03335551, 0.01765233,        nan],\n",
      "       [0.03154257, 0.01911774,        nan],\n",
      "       [0.03362209, 0.01779605,        nan],\n",
      "       [0.03395734, 0.01845783,        nan],\n",
      "       [0.03374495, 0.01668816,        nan],\n",
      "       [0.03286943, 0.01630612,        nan]], dtype=float32), array([[[-0.26014233, -0.07729527,  0.12744105, ..., -0.13610311,\n",
      "         -0.01170746, -0.14214867],\n",
      "        [-0.22678801, -0.0287626 ,  0.12798846, ..., -0.21305987,\n",
      "         -0.07158364, -0.07009518],\n",
      "        [-0.13126121, -0.02895669, -0.01522888, ...,  0.05431576,\n",
      "          0.01547243, -0.07226417],\n",
      "        ...,\n",
      "        [-0.16427527, -0.20580429,  0.09988254, ..., -0.1516815 ,\n",
      "         -0.19835424, -0.1474124 ],\n",
      "        [-0.16312744, -0.21270259,  0.08641566, ..., -0.12796532,\n",
      "         -0.18341427, -0.12903772],\n",
      "        [-0.1748039 , -0.22222036,  0.09039624, ..., -0.13706802,\n",
      "         -0.18264763, -0.11756141]],\n",
      "\n",
      "       [[-0.2704465 , -0.08907659,  0.10588206, ..., -0.11574782,\n",
      "         -0.01549189, -0.16585079],\n",
      "        [-0.27850193, -0.08060674,  0.07315267, ..., -0.22648716,\n",
      "         -0.05814693, -0.09108086],\n",
      "        [-0.17574291, -0.06068707,  0.00211418, ...,  0.03748708,\n",
      "          0.03562687, -0.12329029],\n",
      "        ...,\n",
      "        [ 0.07110681, -0.18167634, -0.00310333, ..., -0.22107081,\n",
      "         -0.02394835, -0.04871878],\n",
      "        [ 0.06768884, -0.17961238,  0.00250084, ..., -0.2165465 ,\n",
      "         -0.01682011, -0.04455885],\n",
      "        [ 0.07358549, -0.1831607 , -0.00291668, ..., -0.22081028,\n",
      "         -0.00685874, -0.037733  ]],\n",
      "\n",
      "       [[-0.24055463, -0.04325673,  0.13562804, ..., -0.15932137,\n",
      "          0.02178921, -0.1597282 ],\n",
      "        [-0.24701142,  0.01236574,  0.10495804, ..., -0.21117152,\n",
      "         -0.02576918, -0.06330304],\n",
      "        [-0.14523993, -0.05104176,  0.03049814, ...,  0.03371712,\n",
      "          0.04481643, -0.067154  ],\n",
      "        ...,\n",
      "        [-0.0281235 , -0.01476677,  0.01184634, ..., -0.06466468,\n",
      "          0.00394266,  0.08868428],\n",
      "        [-0.02467119, -0.00749106,  0.00653061, ..., -0.04545479,\n",
      "          0.00557983,  0.08324187],\n",
      "        [-0.02307609, -0.00854131,  0.00603069, ..., -0.04445627,\n",
      "          0.00592061,  0.07998835]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.1635853 ,  0.03377885,  0.10918761, ..., -0.05040082,\n",
      "         -0.02907189, -0.16272037],\n",
      "        [-0.27184793,  0.00968326, -0.01160446, ..., -0.11875826,\n",
      "         -0.0192291 , -0.08367258],\n",
      "        [-0.10550722,  0.05701738,  0.16702819, ..., -0.09715749,\n",
      "          0.02209814, -0.15879025],\n",
      "        ...,\n",
      "        [-0.03713666, -0.19081526,  0.03801532, ..., -0.00558122,\n",
      "         -0.120956  , -0.09756038],\n",
      "        [-0.02668845, -0.19358148,  0.02731378, ..., -0.0156029 ,\n",
      "         -0.12366433, -0.09582744],\n",
      "        [ 0.01318956, -0.20182651, -0.0086637 , ..., -0.03582901,\n",
      "         -0.1211564 , -0.09027915]],\n",
      "\n",
      "       [[-0.17860682,  0.01703217,  0.11038581, ..., -0.06087018,\n",
      "         -0.02045447, -0.15371546],\n",
      "        [-0.27613026,  0.00565209, -0.01095568, ..., -0.11256369,\n",
      "         -0.03154047, -0.08758934],\n",
      "        [-0.08899873,  0.02119269,  0.15726991, ..., -0.12050579,\n",
      "          0.00943297, -0.15097316],\n",
      "        ...,\n",
      "        [-0.01366232, -0.2006995 ,  0.0247912 , ..., -0.03333975,\n",
      "          0.00319234, -0.07527023],\n",
      "        [-0.01213191, -0.20960176,  0.01793648, ..., -0.04430282,\n",
      "         -0.00188463, -0.07435942],\n",
      "        [-0.01558405, -0.20946771,  0.00503271, ..., -0.04296498,\n",
      "          0.00165964, -0.06842487]],\n",
      "\n",
      "       [[-0.20294665,  0.03862369,  0.1753306 , ..., -0.14500526,\n",
      "          0.02233735, -0.13017173],\n",
      "        [-0.10036635, -0.02071438, -0.11281984, ...,  0.07357495,\n",
      "          0.10233364, -0.0768935 ],\n",
      "        [-0.11843259, -0.04918488, -0.3122552 , ..., -0.1439679 ,\n",
      "          0.00665975, -0.09506473],\n",
      "        ...,\n",
      "        [ 0.05485769,  0.09152063, -0.09345723, ..., -0.01897603,\n",
      "          0.1981619 , -0.0019046 ],\n",
      "        [-0.09046555,  0.12523445, -0.0674496 , ...,  0.00977458,\n",
      "         -0.03931526, -0.04766523],\n",
      "        [-0.00126759,  0.0010451 , -0.00167821, ..., -0.00260624,\n",
      "         -0.00108722,  0.17432915]]], dtype=float32))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtokenized_datasets\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/transformers/trainer.py:3441\u001B[0m, in \u001B[0;36mTrainer.predict\u001B[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[1;32m   3438\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m   3440\u001B[0m eval_loop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39muse_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluation_loop\n\u001B[0;32m-> 3441\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43meval_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3442\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdescription\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPrediction\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric_key_prefix\u001B[49m\n\u001B[1;32m   3443\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3444\u001B[0m total_batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39meval_batch_size \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mworld_size\n\u001B[1;32m   3445\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_jit_compilation_time\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output\u001B[38;5;241m.\u001B[39mmetrics:\n",
      "File \u001B[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/transformers/trainer.py:3664\u001B[0m, in \u001B[0;36mTrainer.evaluation_loop\u001B[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[1;32m   3661\u001B[0m metrics \u001B[38;5;241m=\u001B[39m denumpify_detensorize(metrics)\n\u001B[1;32m   3663\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m all_losses \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 3664\u001B[0m     \u001B[43mmetrics\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mmetric_key_prefix\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m_loss\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m all_losses\u001B[38;5;241m.\u001B[39mmean()\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m   3665\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjit_compilation_time\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m   3666\u001B[0m     metrics[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_jit_compilation_time\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjit_compilation_time\n",
      "\u001B[0;31mTypeError\u001B[0m: 'NoneType' object does not support item assignment"
     ]
    }
   ],
   "execution_count": 21,
   "source": "trainer.predict([tokenized_datasets[\"train\"][i] for i in range(10)])"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T18:48:39.677656Z",
     "start_time": "2024-04-18T18:48:39.675238Z"
    }
   },
   "cell_type": "code",
   "source": "type(p)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "{'label': 2,\n 'input_ids': [71,\n  568,\n  30,\n  3,\n  9,\n  4952,\n  4418,\n  7,\n  147,\n  3,\n  9,\n  4335,\n  323,\n  20527,\n  5,\n  1,\n  71,\n  568,\n  19,\n  761,\n  112,\n  4952,\n  21,\n  3,\n  9,\n  2259,\n  5,\n  1],\n 'attention_mask': [1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1],\n 'labels': [37,\n  568,\n  228,\n  36,\n  761,\n  112,\n  4952,\n  21,\n  3,\n  9,\n  2259,\n  6,\n  68,\n  34,\n  19,\n  59,\n  6539,\n  8,\n  495,\n  5,\n  1]}"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T17:43:21.911036Z",
     "start_time": "2024-04-18T17:43:21.908790Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdata_collator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtokenized_datasets\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/thesis/t5_enc/t5.py:177\u001B[0m, in \u001B[0;36mT5ForConditionalGenerationAndSequenceClassification.forward\u001B[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, label, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    174\u001B[0m \u001B[38;5;66;03m# Encode if needed (training, first prediction pass)\u001B[39;00m\n\u001B[1;32m    175\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m encoder_outputs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    176\u001B[0m     \u001B[38;5;66;03m# Convert encoder inputs in embeddings if needed\u001B[39;00m\n\u001B[0;32m--> 177\u001B[0m     encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m return_dict \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(encoder_outputs, BaseModelOutput):\n\u001B[1;32m    187\u001B[0m     encoder_outputs \u001B[38;5;241m=\u001B[39m BaseModelOutput(\n\u001B[1;32m    188\u001B[0m         last_hidden_state\u001B[38;5;241m=\u001B[39mencoder_outputs[\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m    189\u001B[0m         hidden_states\u001B[38;5;241m=\u001B[39mencoder_outputs[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(encoder_outputs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    190\u001B[0m         attentions\u001B[38;5;241m=\u001B[39mencoder_outputs[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(encoder_outputs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    191\u001B[0m     )\n",
      "File \u001B[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1021\u001B[0m, in \u001B[0;36mT5Stack.forward\u001B[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1019\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_tokens \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1020\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou have to initialize the model with valid token embeddings\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1021\u001B[0m     inputs_embeds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_tokens\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1023\u001B[0m batch_size, seq_length \u001B[38;5;241m=\u001B[39m input_shape\n\u001B[1;32m   1025\u001B[0m \u001B[38;5;66;03m# required mask seq length can be calculated via length of past\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/sparse.py:163\u001B[0m, in \u001B[0;36mEmbedding.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 163\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:2237\u001B[0m, in \u001B[0;36membedding\u001B[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[1;32m   2231\u001B[0m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[1;32m   2232\u001B[0m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[1;32m   2233\u001B[0m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[1;32m   2234\u001B[0m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[1;32m   2235\u001B[0m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[1;32m   2236\u001B[0m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[0;32m-> 2237\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T17:44:03.120982Z",
     "start_time": "2024-04-18T17:44:02.915392Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
